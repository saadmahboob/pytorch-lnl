{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x7f506f242a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from IPython.display import Image\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/ktUOnca.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image at 0x7f5119a7ef10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of neural networks\n",
    "Image(url='https://i.imgur.com/ktUOnca.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Deep Learning?\n",
    "\n",
    "A machine learning strategy for learning representations (embeddings) of data.\n",
    "\n",
    "* **Input:** An input vector for a piece of data you wish to represent.\n",
    "* **Process:** *magic*\n",
    "* **Output:** An embedding for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *magic* ?!?\n",
    "\n",
    "Yes.\n",
    "\n",
    "The process is a neural network. It applies a sequence of functions to the input:\n",
    "\n",
    "* **Input:** $x$\n",
    "* **Output:** $f_n(f_{n-1}(\\dots f_2(f_1(x))\\dots))$\n",
    "* Traditionally, each $f_i$ is a matrix multiplication followed by a nonlinearity (called an *activation function*).\n",
    "* Each fi can basically be anything as long as it is **differentiable**.\n",
    "* We call these $f_i$â€™s *layers*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Basic Linear Layer with ReLU activation function.\n",
    "\n",
    "Let's let \n",
    "* $f_1(x) = \\begin{bmatrix} 1 & 2 \\\\ 4 & 3 \\end{bmatrix}x + \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$, \n",
    "* $f_2(x) = max(0, x)$,\n",
    "* $x = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$\n",
    "\n",
    "So $f_2(f_1(x)) = f_2(\\begin{bmatrix} -1 \\\\ 2\\end{bmatrix})=\\begin{bmatrix}0 \\\\ 2\\end{bmatrix}$\n",
    "\n",
    "* Here, $f_1$ is called a linear layer and $f_2$ is called the ReLU activation function.\n",
    "* Linear layers needn't have the same number of inputs and outputs.\n",
    "* Typically the parameters inside of the matrices of $f_1$ are *learned* in training over a dataset.\n",
    "* This learning is done with backpropogation, and is the reason that we need our layers to be differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## idea behind backprop\n",
    "* You have an input $x$ with a target output $t$.\n",
    "* Pass the input $x$ through the series of layers to get an output $y=f_n(\\dots f_1(x)\\dots)$\n",
    "* Calculate some error $e$ on $y$ with respect to the target output $t$ (e.g. from classification or regression).\n",
    "* That error is called the *loss* and you want to learn parameters in your $f_i$'s that minimize it.\n",
    "### **WARNING!!! MATH AHEAD**\n",
    "* For each parameter $p$ in your $f_i$'s, you can calculate the derivative $\\frac{de}{dp}$ via repeated use of the chain rule and use that derivative (called a gradient) to update the parameter $p$ to reduce your loss.\n",
    "* this process is called *backpropogation*, since it moves backwards through the network.\n",
    "* Since the derivative of a parameter is calculated with respect to the derivatives of all downstream parameters, any parameter that depends on a parameter which is learned needs a gradient.\n",
    "\n",
    "### Practical notes:\n",
    "* A loss is typically defined as the sum of the individual losses over the entire dataset.\n",
    "* It is too expensive to compute the loss for the entire dataset before updating the parameters.\n",
    "* Updating parameters for every single example tends to be too chaotic to get the model to converge.\n",
    "* We instead process the data in random batches as a hybrid of the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.frank-dieterle.de/phd/images/image016.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image at 0x7f5119a7efd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://www.frank-dieterle.de/phd/images/image016.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how this works in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0\n",
       " 0  0  0\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how tensors work\n",
    "x = torch.zeros(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: Variable containing:\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "requires grad: False\n",
      "data: \n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how variables work\n",
    "x = Variable(x)\n",
    "print \"x:\", x\n",
    "print \"requires grad:\", x.requires_grad\n",
    "print \"data:\", x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "does y require grad? False\n",
      "does w require grad? True\n"
     ]
    }
   ],
   "source": [
    "y = x + 1\n",
    "z = Variable(torch.ones(2,3), requires_grad=True)\n",
    "w = y+z\n",
    "\n",
    "print y\n",
    "print \"does y require grad?\", y.requires_grad\n",
    "print \"does w require grad?\", w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " -0.5403  0.1461 -0.1120\n",
       "  0.2643  0.2523 -0.5687\n",
       "  0.3951 -0.4703  0.0070\n",
       "  0.0127  0.4424  0.3770\n",
       " [torch.FloatTensor of size 4x3], Parameter containing:\n",
       "  0.0275\n",
       " -0.2266\n",
       " -0.2756\n",
       "  0.0264\n",
       " [torch.FloatTensor of size 4]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about neural network layers?\n",
    "lin = nn.Linear(3, 4)  # 3 inputs and 4 outputs. Should contain a 4x3 matrix and a 4x1 matrix of parameters.\n",
    "list(lin.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin output Variable containing:\n",
      " 0.3216  0.0921  0.3608 -1.2713\n",
      " 0.3216  0.0921  0.3608 -1.2713\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print \"lin output\", lin(y)  # processing with a batch size of 2.\n",
    "print lin(y).requires_grad\n",
    "print lin(w).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3216  0.0921  0.3608  0.0000\n",
      " 0.3216  0.0921  0.3608  0.0000\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "print relu(lin(y))\n",
    "print relu(lin(y)).requires_grad\n",
    "print relu(w).requires_grad\n",
    "print relu(y).requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinds of data and their layers:\n",
    "## Convolutional layers (good for image data).\n",
    "* An $m\\times n$ image with $3$ color channels is $m\\times n \\times 3$ dimensional. \n",
    "* For $m=n=200$, $m\\times n \\times 3 = 120000$, which is a lot of inputs for a linear layer to take in right away. Suppose you wanted to have an output dimension of 64. That would require $120000\\times 64 + 64 = 7680064$ parameters.\n",
    "* **Idea:** why not use the fact that patches of regions across the image have similar patterns? If we use this fact, then a lot of weights over the entire image can actually be the same.\n",
    "* Let's focus on learning to get good with $3\\times 3$ patches for now...\n",
    "* A convolutional network over $3\\times 3$ patches with the same number of inputs and outputs as above will have a set of $3 \\times 3 \\times 3 \\times 64 + 64= 1792$ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.stack.imgur.com/GvsBA.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image at 0x7f5119a7ee90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.stack.imgur.com/GvsBA.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent layers (good for sequential data).\n",
    "* Suppose you have a training set of sentences for sentiment classification.\n",
    "* Each sentence has either positive, negative, or neutral sentiment.\n",
    "* How do you feed that through a model?\n",
    "* Concatenate the word2vec word embeddings for the words together and use that as input?\n",
    "* **Problem:** sentences are variable length. \n",
    "* You could just grab the first $N$ words of the sentence, but that probably won't do too well at detecting sentiment. Also, you'd have an input size of $N\\times m$ where $m$ is the size of your word embeddings.\n",
    "### Alternative approach: use a recurrent layer.\n",
    "* Holds an internal *state* vector for the built up representation of the sequence up until that point.\n",
    "* Could process word embeddings one at a time and learn to output the sentiment at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image at 0x7f5119a7eed0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up datasets.\n",
    "training = DataLoader(\n",
    "    MNIST(\n",
    "        \"./train\", \n",
    "        download=False, \n",
    "        transform=Compose([ToTensor(),Normalize((0.1307,), (0.3081,))])\n",
    "    ), \n",
    "    batch_size=64, \n",
    "    shuffle=True, \n",
    "    num_workers=40\n",
    ")\n",
    "testing = DataLoader(\n",
    "    MNIST(\n",
    "        \"./test\", \n",
    "        train=False,\n",
    "        download=False, \n",
    "        transform=Compose([ToTensor(),Normalize((0.1307,), (0.3081,))])\n",
    "    ), \n",
    "    batch_size=64, \n",
    "    shuffle=True, \n",
    "    num_workers=40\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training.dataset), len(testing.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x7F511CBB4590>, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F506EF17C50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print MNIST('./train')[0]\n",
    "MNIST('./train')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic linear with relu's\n",
    "class LinReLU(nn.Module):\n",
    "    def __init__(self, indim, outdim):\n",
    "        super(LinReLU, self).__init__()\n",
    "        self.lin = nn.Linear(indim, outdim)\n",
    "        self.relu = nn.ReLU(True)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = self.lin(input)\n",
    "        return self.relu(input)\n",
    "\n",
    "\n",
    "class MnistLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistLinear, self).__init__()\n",
    "        self.lin1 = LinReLU(28*28, 16)\n",
    "        self.lin2 = nn.Linear(16, 10)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = self.lin1(input.view(-1, 28*28))\n",
    "        input = self.lin2(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel=3):\n",
    "        super(ConvReLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel, padding=kernel/2)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = self.conv(input)\n",
    "        input = self.relu(input)\n",
    "        return self.bn(input)\n",
    "\n",
    "\n",
    "class MnistCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCNN, self).__init__()\n",
    "        self.conv1 = ConvReLU(1, 16)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.conv2 = ConvReLU(16, 32)\n",
    "        self.avgpool = nn.AvgPool2d(14)\n",
    "        self.lin = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.mp(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.avgpool(input).squeeze()\n",
    "        return self.lin(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MnistRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=28, \n",
    "            hidden_size=16, \n",
    "            num_layers=2, \n",
    "            batch_first=True, \n",
    "            dropout=0.5\n",
    "        )\n",
    "        self.linear = nn.Linear(16, 10)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input, hidden = self.lstm(input.squeeze())\n",
    "        return self.linear(input[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ComboModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComboModel, self).__init__()\n",
    "        self.lin = MnistLinear()\n",
    "        self.cnn = MnistCNN()\n",
    "        self.rnn = MnistRNN()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        l1 = self.lin(input)\n",
    "        l2 = self.cnn(input)\n",
    "        l3 = self.rnn(input)\n",
    "        return l1, l2, l3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ComboModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params for linear:\t12730\n",
      "num params for cnn:\t5226\n",
      "num params for rnn:\t5290\n"
     ]
    }
   ],
   "source": [
    "def num_parameters(m):\n",
    "    return sum([y.nelement() for y in m.parameters()])\n",
    "\n",
    "print \"num params for linear:\\t\", num_parameters(model.lin)\n",
    "print \"num params for cnn:\\t\", num_parameters(model.cnn)\n",
    "print \"num params for rnn:\\t\", num_parameters(model.rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss().cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Test set: Average loss: 2.3522, Accuracy: 1105/10000 (11%)\n",
      "\n",
      "CNN Test set: Average loss: 2.3099, Accuracy: 974/10000 (10%)\n",
      "\n",
      "RNN Test set: Average loss: 2.3116, Accuracy: 974/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/938 (0%)]\tLin Loss: 2.308277\tCNN Loss: 2.316426\tRNN Loss: 2.308771\n",
      "Train Epoch: 1 [100/938 (11%)]\tLin Loss: 1.472899\tCNN Loss: 1.754471\tRNN Loss: 2.240767\n",
      "Train Epoch: 1 [200/938 (21%)]\tLin Loss: 0.468504\tCNN Loss: 0.889403\tRNN Loss: 1.705237\n",
      "Train Epoch: 1 [300/938 (32%)]\tLin Loss: 0.266181\tCNN Loss: 0.397529\tRNN Loss: 1.179084\n",
      "Train Epoch: 1 [400/938 (43%)]\tLin Loss: 0.140255\tCNN Loss: 0.269138\tRNN Loss: 0.977627\n",
      "Train Epoch: 1 [500/938 (53%)]\tLin Loss: 0.233862\tCNN Loss: 0.236546\tRNN Loss: 0.647767\n",
      "Train Epoch: 1 [600/938 (64%)]\tLin Loss: 0.182968\tCNN Loss: 0.215670\tRNN Loss: 0.458684\n",
      "Train Epoch: 1 [700/938 (75%)]\tLin Loss: 0.280577\tCNN Loss: 0.170136\tRNN Loss: 0.435829\n",
      "Train Epoch: 1 [800/938 (85%)]\tLin Loss: 0.171542\tCNN Loss: 0.073429\tRNN Loss: 0.326413\n",
      "Train Epoch: 1 [900/938 (96%)]\tLin Loss: 0.252601\tCNN Loss: 0.288123\tRNN Loss: 0.415597\n",
      "Linear Test set: Average loss: 0.2729, Accuracy: 9200/10000 (92%)\n",
      "\n",
      "CNN Test set: Average loss: 0.2174, Accuracy: 9371/10000 (94%)\n",
      "\n",
      "RNN Test set: Average loss: 0.3547, Accuracy: 8913/10000 (89%)\n",
      "\n",
      "Train Epoch: 2 [0/938 (0%)]\tLin Loss: 0.099280\tCNN Loss: 0.152244\tRNN Loss: 0.387579\n",
      "Train Epoch: 2 [100/938 (11%)]\tLin Loss: 0.514532\tCNN Loss: 0.239423\tRNN Loss: 0.507482\n",
      "Train Epoch: 2 [200/938 (21%)]\tLin Loss: 0.801450\tCNN Loss: 0.153613\tRNN Loss: 0.472816\n",
      "Train Epoch: 2 [300/938 (32%)]\tLin Loss: 0.399490\tCNN Loss: 0.136088\tRNN Loss: 0.147009\n",
      "Train Epoch: 2 [400/938 (43%)]\tLin Loss: 0.325585\tCNN Loss: 0.087188\tRNN Loss: 0.276675\n",
      "Train Epoch: 2 [500/938 (53%)]\tLin Loss: 0.161132\tCNN Loss: 0.173507\tRNN Loss: 0.459642\n",
      "Train Epoch: 2 [600/938 (64%)]\tLin Loss: 0.389951\tCNN Loss: 0.060454\tRNN Loss: 0.374665\n",
      "Train Epoch: 2 [700/938 (75%)]\tLin Loss: 0.408693\tCNN Loss: 0.178022\tRNN Loss: 0.361216\n",
      "Train Epoch: 2 [800/938 (85%)]\tLin Loss: 0.670359\tCNN Loss: 0.086416\tRNN Loss: 0.168455\n",
      "Train Epoch: 2 [900/938 (96%)]\tLin Loss: 0.439441\tCNN Loss: 0.203209\tRNN Loss: 0.152842\n",
      "Linear Test set: Average loss: 0.2618, Accuracy: 9271/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.1957, Accuracy: 9387/10000 (94%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1882, Accuracy: 9445/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/938 (0%)]\tLin Loss: 0.196576\tCNN Loss: 0.099477\tRNN Loss: 0.184011\n",
      "Train Epoch: 3 [100/938 (11%)]\tLin Loss: 0.610010\tCNN Loss: 0.107452\tRNN Loss: 0.437228\n",
      "Train Epoch: 3 [200/938 (21%)]\tLin Loss: 0.479452\tCNN Loss: 0.087217\tRNN Loss: 0.470572\n",
      "Train Epoch: 3 [300/938 (32%)]\tLin Loss: 0.209959\tCNN Loss: 0.158149\tRNN Loss: 0.379473\n",
      "Train Epoch: 3 [400/938 (43%)]\tLin Loss: 0.244268\tCNN Loss: 0.162043\tRNN Loss: 0.218383\n",
      "Train Epoch: 3 [500/938 (53%)]\tLin Loss: 0.362650\tCNN Loss: 0.124342\tRNN Loss: 0.232398\n",
      "Train Epoch: 3 [600/938 (64%)]\tLin Loss: 0.240374\tCNN Loss: 0.134583\tRNN Loss: 0.214285\n",
      "Train Epoch: 3 [700/938 (75%)]\tLin Loss: 0.222404\tCNN Loss: 0.188754\tRNN Loss: 0.133511\n",
      "Train Epoch: 3 [800/938 (85%)]\tLin Loss: 0.598202\tCNN Loss: 0.243258\tRNN Loss: 0.180831\n",
      "Train Epoch: 3 [900/938 (96%)]\tLin Loss: 0.197530\tCNN Loss: 0.042706\tRNN Loss: 0.210542\n",
      "Linear Test set: Average loss: 0.2716, Accuracy: 9267/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0976, Accuracy: 9711/10000 (97%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1757, Accuracy: 9477/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/938 (0%)]\tLin Loss: 0.115343\tCNN Loss: 0.077257\tRNN Loss: 0.188449\n",
      "Train Epoch: 4 [100/938 (11%)]\tLin Loss: 0.090964\tCNN Loss: 0.130549\tRNN Loss: 0.264037\n",
      "Train Epoch: 4 [200/938 (21%)]\tLin Loss: 0.317609\tCNN Loss: 0.018567\tRNN Loss: 0.142481\n",
      "Train Epoch: 4 [300/938 (32%)]\tLin Loss: 0.226060\tCNN Loss: 0.114083\tRNN Loss: 0.067159\n",
      "Train Epoch: 4 [400/938 (43%)]\tLin Loss: 0.168269\tCNN Loss: 0.034430\tRNN Loss: 0.178887\n",
      "Train Epoch: 4 [500/938 (53%)]\tLin Loss: 0.139017\tCNN Loss: 0.125741\tRNN Loss: 0.143321\n",
      "Train Epoch: 4 [600/938 (64%)]\tLin Loss: 0.184266\tCNN Loss: 0.063634\tRNN Loss: 0.102029\n",
      "Train Epoch: 4 [700/938 (75%)]\tLin Loss: 0.278228\tCNN Loss: 0.044368\tRNN Loss: 0.152966\n",
      "Train Epoch: 4 [800/938 (85%)]\tLin Loss: 0.308153\tCNN Loss: 0.208461\tRNN Loss: 0.192085\n",
      "Train Epoch: 4 [900/938 (96%)]\tLin Loss: 0.135762\tCNN Loss: 0.031332\tRNN Loss: 0.375858\n",
      "Linear Test set: Average loss: 0.2660, Accuracy: 9288/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.1180, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1742, Accuracy: 9479/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/938 (0%)]\tLin Loss: 0.094426\tCNN Loss: 0.117785\tRNN Loss: 0.236241\n",
      "Train Epoch: 5 [100/938 (11%)]\tLin Loss: 0.146854\tCNN Loss: 0.084040\tRNN Loss: 0.090728\n",
      "Train Epoch: 5 [200/938 (21%)]\tLin Loss: 0.189145\tCNN Loss: 0.107128\tRNN Loss: 0.231946\n",
      "Train Epoch: 5 [300/938 (32%)]\tLin Loss: 0.130012\tCNN Loss: 0.090731\tRNN Loss: 0.118476\n",
      "Train Epoch: 5 [400/938 (43%)]\tLin Loss: 0.118476\tCNN Loss: 0.069209\tRNN Loss: 0.079311\n",
      "Train Epoch: 5 [500/938 (53%)]\tLin Loss: 0.178610\tCNN Loss: 0.046435\tRNN Loss: 0.089306\n",
      "Train Epoch: 5 [600/938 (64%)]\tLin Loss: 0.282795\tCNN Loss: 0.086483\tRNN Loss: 0.456393\n",
      "Train Epoch: 5 [700/938 (75%)]\tLin Loss: 0.203159\tCNN Loss: 0.098564\tRNN Loss: 0.127742\n",
      "Train Epoch: 5 [800/938 (85%)]\tLin Loss: 0.151524\tCNN Loss: 0.062417\tRNN Loss: 0.099833\n",
      "Train Epoch: 5 [900/938 (96%)]\tLin Loss: 0.300595\tCNN Loss: 0.124619\tRNN Loss: 0.239633\n",
      "Linear Test set: Average loss: 0.2545, Accuracy: 9323/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0957, Accuracy: 9721/10000 (97%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1335, Accuracy: 9623/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/938 (0%)]\tLin Loss: 0.175093\tCNN Loss: 0.054688\tRNN Loss: 0.228445\n",
      "Train Epoch: 6 [100/938 (11%)]\tLin Loss: 0.304494\tCNN Loss: 0.154504\tRNN Loss: 0.135925\n",
      "Train Epoch: 6 [200/938 (21%)]\tLin Loss: 0.138777\tCNN Loss: 0.045578\tRNN Loss: 0.095867\n",
      "Train Epoch: 6 [300/938 (32%)]\tLin Loss: 0.111816\tCNN Loss: 0.043370\tRNN Loss: 0.173268\n",
      "Train Epoch: 6 [400/938 (43%)]\tLin Loss: 0.364563\tCNN Loss: 0.105844\tRNN Loss: 0.144686\n",
      "Train Epoch: 6 [500/938 (53%)]\tLin Loss: 0.361122\tCNN Loss: 0.089059\tRNN Loss: 0.275126\n",
      "Train Epoch: 6 [600/938 (64%)]\tLin Loss: 0.184422\tCNN Loss: 0.082710\tRNN Loss: 0.266638\n",
      "Train Epoch: 6 [700/938 (75%)]\tLin Loss: 0.131131\tCNN Loss: 0.092682\tRNN Loss: 0.291825\n",
      "Train Epoch: 6 [800/938 (85%)]\tLin Loss: 0.184700\tCNN Loss: 0.072815\tRNN Loss: 0.163004\n",
      "Train Epoch: 6 [900/938 (96%)]\tLin Loss: 0.099491\tCNN Loss: 0.017486\tRNN Loss: 0.055626\n",
      "Linear Test set: Average loss: 0.2815, Accuracy: 9275/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0712, Accuracy: 9783/10000 (98%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1428, Accuracy: 9579/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/938 (0%)]\tLin Loss: 0.248153\tCNN Loss: 0.038929\tRNN Loss: 0.048396\n",
      "Train Epoch: 7 [100/938 (11%)]\tLin Loss: 0.442507\tCNN Loss: 0.049923\tRNN Loss: 0.151311\n",
      "Train Epoch: 7 [200/938 (21%)]\tLin Loss: 0.207377\tCNN Loss: 0.144877\tRNN Loss: 0.178507\n",
      "Train Epoch: 7 [300/938 (32%)]\tLin Loss: 0.665595\tCNN Loss: 0.061349\tRNN Loss: 0.391456\n",
      "Train Epoch: 7 [400/938 (43%)]\tLin Loss: 0.058378\tCNN Loss: 0.170656\tRNN Loss: 0.141107\n",
      "Train Epoch: 7 [500/938 (53%)]\tLin Loss: 0.187999\tCNN Loss: 0.077278\tRNN Loss: 0.138450\n",
      "Train Epoch: 7 [600/938 (64%)]\tLin Loss: 0.216733\tCNN Loss: 0.031018\tRNN Loss: 0.078898\n",
      "Train Epoch: 7 [700/938 (75%)]\tLin Loss: 0.178478\tCNN Loss: 0.033605\tRNN Loss: 0.119503\n",
      "Train Epoch: 7 [800/938 (85%)]\tLin Loss: 0.282441\tCNN Loss: 0.066741\tRNN Loss: 0.197835\n",
      "Train Epoch: 7 [900/938 (96%)]\tLin Loss: 0.143224\tCNN Loss: 0.156049\tRNN Loss: 0.112789\n",
      "Linear Test set: Average loss: 0.2845, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0738, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1467, Accuracy: 9576/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/938 (0%)]\tLin Loss: 0.258364\tCNN Loss: 0.090503\tRNN Loss: 0.157671\n",
      "Train Epoch: 8 [100/938 (11%)]\tLin Loss: 0.295168\tCNN Loss: 0.180643\tRNN Loss: 0.248164\n",
      "Train Epoch: 8 [200/938 (21%)]\tLin Loss: 0.210790\tCNN Loss: 0.126706\tRNN Loss: 0.150861\n",
      "Train Epoch: 8 [300/938 (32%)]\tLin Loss: 0.197176\tCNN Loss: 0.040429\tRNN Loss: 0.084383\n",
      "Train Epoch: 8 [400/938 (43%)]\tLin Loss: 0.495555\tCNN Loss: 0.210976\tRNN Loss: 0.214906\n",
      "Train Epoch: 8 [500/938 (53%)]\tLin Loss: 0.271455\tCNN Loss: 0.034483\tRNN Loss: 0.166868\n",
      "Train Epoch: 8 [600/938 (64%)]\tLin Loss: 0.443787\tCNN Loss: 0.111096\tRNN Loss: 0.227682\n",
      "Train Epoch: 8 [700/938 (75%)]\tLin Loss: 0.184147\tCNN Loss: 0.028146\tRNN Loss: 0.251597\n",
      "Train Epoch: 8 [800/938 (85%)]\tLin Loss: 0.219663\tCNN Loss: 0.076024\tRNN Loss: 0.158398\n",
      "Train Epoch: 8 [900/938 (96%)]\tLin Loss: 0.133283\tCNN Loss: 0.049717\tRNN Loss: 0.121057\n",
      "Linear Test set: Average loss: 0.2471, Accuracy: 9378/10000 (94%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0965, Accuracy: 9689/10000 (97%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1177, Accuracy: 9653/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/938 (0%)]\tLin Loss: 0.219470\tCNN Loss: 0.023547\tRNN Loss: 0.095078\n",
      "Train Epoch: 9 [100/938 (11%)]\tLin Loss: 0.138714\tCNN Loss: 0.057117\tRNN Loss: 0.129221\n",
      "Train Epoch: 9 [200/938 (21%)]\tLin Loss: 0.261567\tCNN Loss: 0.027200\tRNN Loss: 0.088380\n",
      "Train Epoch: 9 [300/938 (32%)]\tLin Loss: 0.271450\tCNN Loss: 0.119935\tRNN Loss: 0.113861\n",
      "Train Epoch: 9 [400/938 (43%)]\tLin Loss: 0.102586\tCNN Loss: 0.047958\tRNN Loss: 0.126812\n",
      "Train Epoch: 9 [500/938 (53%)]\tLin Loss: 0.180329\tCNN Loss: 0.025029\tRNN Loss: 0.134571\n",
      "Train Epoch: 9 [600/938 (64%)]\tLin Loss: 0.381520\tCNN Loss: 0.039232\tRNN Loss: 0.060942\n",
      "Train Epoch: 9 [700/938 (75%)]\tLin Loss: 0.682165\tCNN Loss: 0.136068\tRNN Loss: 0.187193\n",
      "Train Epoch: 9 [800/938 (85%)]\tLin Loss: 0.149716\tCNN Loss: 0.007794\tRNN Loss: 0.164264\n",
      "Train Epoch: 9 [900/938 (96%)]\tLin Loss: 0.041896\tCNN Loss: 0.148746\tRNN Loss: 0.104267\n",
      "Linear Test set: Average loss: 0.2686, Accuracy: 9323/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0720, Accuracy: 9771/10000 (98%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1184, Accuracy: 9668/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/938 (0%)]\tLin Loss: 0.452675\tCNN Loss: 0.063321\tRNN Loss: 0.132985\n",
      "Train Epoch: 10 [100/938 (11%)]\tLin Loss: 0.082971\tCNN Loss: 0.006599\tRNN Loss: 0.078269\n",
      "Train Epoch: 10 [200/938 (21%)]\tLin Loss: 0.219936\tCNN Loss: 0.018607\tRNN Loss: 0.025145\n",
      "Train Epoch: 10 [300/938 (32%)]\tLin Loss: 0.122672\tCNN Loss: 0.055825\tRNN Loss: 0.127256\n",
      "Train Epoch: 10 [400/938 (43%)]\tLin Loss: 0.095674\tCNN Loss: 0.020409\tRNN Loss: 0.196153\n",
      "Train Epoch: 10 [500/938 (53%)]\tLin Loss: 0.143676\tCNN Loss: 0.041972\tRNN Loss: 0.081423\n",
      "Train Epoch: 10 [600/938 (64%)]\tLin Loss: 0.489853\tCNN Loss: 0.033371\tRNN Loss: 0.092389\n",
      "Train Epoch: 10 [700/938 (75%)]\tLin Loss: 0.048300\tCNN Loss: 0.031704\tRNN Loss: 0.132824\n",
      "Train Epoch: 10 [800/938 (85%)]\tLin Loss: 0.376597\tCNN Loss: 0.013090\tRNN Loss: 0.107753\n",
      "Train Epoch: 10 [900/938 (96%)]\tLin Loss: 0.333190\tCNN Loss: 0.163381\tRNN Loss: 0.208101\n",
      "Linear Test set: Average loss: 0.2510, Accuracy: 9326/10000 (93%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0764, Accuracy: 9761/10000 (98%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1183, Accuracy: 9672/10000 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/938 (0%)]\tLin Loss: 0.176803\tCNN Loss: 0.064817\tRNN Loss: 0.230022\n",
      "Train Epoch: 11 [100/938 (11%)]\tLin Loss: 0.058506\tCNN Loss: 0.037959\tRNN Loss: 0.126352\n",
      "Train Epoch: 11 [200/938 (21%)]\tLin Loss: 0.313369\tCNN Loss: 0.120276\tRNN Loss: 0.318945\n",
      "Train Epoch: 11 [300/938 (32%)]\tLin Loss: 0.244580\tCNN Loss: 0.053202\tRNN Loss: 0.197168\n",
      "Train Epoch: 11 [400/938 (43%)]\tLin Loss: 0.325759\tCNN Loss: 0.155424\tRNN Loss: 0.129407\n",
      "Train Epoch: 11 [500/938 (53%)]\tLin Loss: 0.178115\tCNN Loss: 0.101289\tRNN Loss: 0.080652\n",
      "Train Epoch: 11 [600/938 (64%)]\tLin Loss: 0.388112\tCNN Loss: 0.140400\tRNN Loss: 0.346446\n",
      "Train Epoch: 11 [700/938 (75%)]\tLin Loss: 0.227972\tCNN Loss: 0.134157\tRNN Loss: 0.097882\n",
      "Train Epoch: 11 [800/938 (85%)]\tLin Loss: 0.160200\tCNN Loss: 0.077792\tRNN Loss: 0.135795\n",
      "Train Epoch: 11 [900/938 (96%)]\tLin Loss: 0.095356\tCNN Loss: 0.048117\tRNN Loss: 0.125996\n",
      "Linear Test set: Average loss: 0.2546, Accuracy: 9357/10000 (94%)\n",
      "\n",
      "CNN Test set: Average loss: 0.0602, Accuracy: 9809/10000 (98%)\n",
      "\n",
      "RNN Test set: Average loss: 0.1301, Accuracy: 9621/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(training):\n",
    "        data, target = data.cuda(1), target.cuda(1)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        lin_out, cnn_out, rnn_out = model(data)\n",
    "        lin_loss = loss(lin_out, target)\n",
    "        cnn_loss = loss(cnn_out, target)\n",
    "        rnn_loss = loss(rnn_out, target)\n",
    "        total_loss = lin_loss + cnn_loss + rnn_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLin Loss: {:.6f}\\tCNN Loss: {:.6f}\\tRNN Loss: {:.6f}'.format(\n",
    "                epoch+1, batch_idx, len(training),\n",
    "                100. * batch_idx / len(training), lin_loss.data[0], cnn_loss.data[0], rnn_loss.data[0]))\n",
    "\n",
    "num_epochs = 10\n",
    "losses = [{}] * (num_epochs+1)\n",
    "correct = [{}] * (num_epochs+1)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    losses[epoch] = dict(\n",
    "        Linear=0,\n",
    "        CNN=0,\n",
    "        RNN=0\n",
    "    )\n",
    "    correct[epoch] = dict(\n",
    "        Linear=0,\n",
    "        CNN=0,\n",
    "        RNN=0\n",
    "    )\n",
    "    for data, target in testing:\n",
    "        data, target = data.cuda(1), target.cuda(1)\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        lin_out, cnn_out, rnn_out = model(data)\n",
    "        \n",
    "        for name, output in [(\"Linear\", lin_out), (\"CNN\", cnn_out), (\"RNN\", rnn_out)]:\n",
    "            losses[epoch][name] += loss(output, target).data[0]\n",
    "            pred = output.data.max(1)[1] \n",
    "            correct[epoch][name] += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    for name in ['Linear', 'CNN', 'RNN']:\n",
    "        losses[epoch][name] /= len(testing) # loss function already averages over batch size\n",
    "        print('{} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            name, losses[epoch][name], correct[epoch][name], len(testing.dataset),\n",
    "            100. * correct[epoch][name] / len(testing.dataset)))\n",
    "        \n",
    "for epoch in range(num_epochs+1):\n",
    "    test(epoch)\n",
    "    train(epoch)\n",
    "test(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1105, 0.92, 0.9271, 0.9267, 0.9288, 0.9323, 0.9275, 0.9292, 0.9378, 0.9323, 0.9357]\n",
      "[0.0974, 0.9371, 0.9387, 0.9711, 0.9645, 0.9721, 0.9783, 0.978, 0.9689, 0.9771, 0.9809]\n",
      "[0.0974, 0.8913, 0.9445, 0.9477, 0.9479, 0.9623, 0.9579, 0.9576, 0.9653, 0.9668, 0.9621]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"166b8525-cae5-4015-a0a4-61aaacfb3dd7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"166b8525-cae5-4015-a0a4-61aaacfb3dd7\", [{\"y\": [0.1105, 0.92, 0.9271, 0.9267, 0.9288, 0.9323, 0.9275, 0.9292, 0.9378, 0.9323, 0.9357], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"type\": \"scatter\", \"name\": \"Linear\"}, {\"y\": [0.0974, 0.9371, 0.9387, 0.9711, 0.9645, 0.9721, 0.9783, 0.978, 0.9689, 0.9771, 0.9809], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"type\": \"scatter\", \"name\": \"CNN\"}, {\"y\": [0.0974, 0.8913, 0.9445, 0.9477, 0.9479, 0.9623, 0.9579, 0.9576, 0.9653, 0.9668, 0.9621], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"type\": \"scatter\", \"name\": \"RNN\"}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x7f506f242f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatters = []\n",
    "for name in ['Linear', 'CNN', 'RNN']:\n",
    "    xs = [i for i in range(1, num_epochs+1)]\n",
    "    ys = [float(i[name])/len(testing.dataset) for i in correct]\n",
    "    scatters.append(go.Scatter(\n",
    "        x = xs,\n",
    "        y = ys,\n",
    "        name=name\n",
    "    ))\n",
    "    print ys\n",
    "iplot(scatters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pytorch.org/docs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
